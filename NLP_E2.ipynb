{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"executionInfo":{"elapsed":285131,"status":"ok","timestamp":1732264733243,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"},"user_tz":-60},"id":"_wxt1f33Wugp","outputId":"cb27250c-0581-4fbc-d979-5d605e0e4758"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting allennlp\n","  Downloading allennlp-2.10.1-py3-none-any.whl.metadata (21 kB)\n","Collecting torch<1.13.0,>=1.10.0 (from allennlp)\n","  Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl.metadata (22 kB)\n","Collecting torchvision<0.14.0,>=0.8.1 (from allennlp)\n","  Downloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (10 kB)\n","Collecting cached-path<1.2.0,>=1.1.3 (from allennlp)\n","  Downloading cached_path-1.1.6-py3-none-any.whl.metadata (6.0 kB)\n","Collecting fairscale==0.4.6 (from allennlp)\n","  Downloading fairscale-0.4.6.tar.gz (248 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.9.1)\n","Collecting spacy<3.4,>=2.1.0 (from allennlp)\n","  Downloading spacy-3.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n","Requirement already satisfied: numpy>=1.21.4 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.26.4)\n","Collecting tensorboardX>=1.2 (from allennlp)\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from allennlp) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.10/dist-packages (from allennlp) (4.66.6)\n","Requirement already satisfied: h5py>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.12.1)\n","Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.5.2)\n","Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.13.1)\n","Requirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.10/dist-packages (from allennlp) (8.3.3)\n","Collecting transformers<4.21,>=4.1 (from allennlp)\n","  Downloading transformers-4.20.1-py3-none-any.whl.metadata (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.3/77.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sentencepiece>=0.1.96 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.2.0)\n","Collecting filelock<3.8,>=3.3 (from allennlp)\n","  Downloading filelock-3.7.1-py3-none-any.whl.metadata (2.5 kB)\n","Collecting lmdb>=1.2.1 (from allennlp)\n","  Downloading lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n","Requirement already satisfied: more-itertools>=8.12.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (10.5.0)\n","Collecting termcolor==1.1.0 (from allennlp)\n","  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting wandb<0.13.0,>=0.10.0 (from allennlp)\n","  Downloading wandb-0.12.21-py2.py3-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: huggingface-hub>=0.0.16 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.26.2)\n","Collecting dill>=0.3.4 (from allennlp)\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Collecting base58>=2.1.1 (from allennlp)\n","  Downloading base58-2.1.1-py3-none-any.whl.metadata (3.1 kB)\n","Collecting sacremoses (from allennlp)\n","  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n","Requirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.13.0)\n","Collecting protobuf<4.0.0,>=3.12.0 (from allennlp)\n","  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n","Requirement already satisfied: traitlets>5.1.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (5.7.1)\n","Collecting jsonnet>=0.10.0 (from allennlp)\n","  Downloading jsonnet-0.20.0.tar.gz (594 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.2/594.2 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting rich<13.0,>=12.1 (from cached-path<1.2.0,>=1.1.3->allennlp)\n","  Downloading rich-12.6.0-py3-none-any.whl.metadata (18 kB)\n","\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/boto3/\u001b[0m\u001b[33m\n","\u001b[0mCollecting boto3<2.0,>=1.0 (from cached-path<1.2.0,>=1.1.3->allennlp)\n","  Downloading boto3-1.35.67-py3-none-any.whl.metadata (6.7 kB)\n","Requirement already satisfied: google-cloud-storage<3.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (2.8.0)\n","Collecting huggingface-hub>=0.0.16 (from allennlp)\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.16->allennlp) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.12.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.16->allennlp) (24.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->allennlp) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->allennlp) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->allennlp) (2024.9.11)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (2.0.0)\n","Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (1.5.0)\n","Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (1.2.2)\n","Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (2.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (2024.8.30)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.1->allennlp) (3.5.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.9)\n","Collecting thinc<8.1.0,>=8.0.14 (from spacy<3.4,>=2.1.0->allennlp)\n","  Downloading thinc-8.0.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.7.11)\n","Collecting wasabi<1.1.0,>=0.9.1 (from spacy<3.4,>=2.1.0->allennlp)\n","  Downloading wasabi-0.10.1-py3-none-any.whl.metadata (28 kB)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.10)\n","Collecting typer>=0.4.1 (from allennlp)\n","  Downloading typer-0.4.2-py3-none-any.whl.metadata (12 kB)\n","Collecting pathy>=0.3.5 (from spacy<3.4,>=2.1.0->allennlp)\n","  Downloading pathy-0.11.0-py3-none-any.whl.metadata (16 kB)\n","Collecting smart-open<7.0.0,>=5.2.1 (from spacy<3.4,>=2.1.0->allennlp)\n","  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 (from spacy<3.4,>=2.1.0->allennlp)\n","  Downloading pydantic-1.8.2-py3-none-any.whl.metadata (103 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (75.1.0)\n","Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.0.16->allennlp)\n","  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.4.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision<0.14.0,>=0.8.1->allennlp) (11.0.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers<4.21,>=4.1->allennlp)\n","  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.5 kB)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (3.1.43)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n","Collecting shortuuid>=0.5.0 (from wandb<0.13.0,>=0.10.0->allennlp)\n","  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.9.5)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.18.0)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.16.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (0.4.0)\n","Collecting pathtools (from wandb<0.13.0,>=0.10.0->allennlp)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.3.4)\n","Collecting botocore<1.36.0,>=1.35.67 (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp)\n","  Downloading botocore-1.35.67-py3-none-any.whl.metadata (5.7 kB)\n","Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp)\n","  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n","Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp)\n","  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp) (4.0.11)\n","Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.27.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.19.2)\n","Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.4.1)\n","Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.7.2)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.4,>=2.1.0->allennlp) (1.2.0)\n","Collecting pathlib-abc==0.1.1 (from pathy>=0.3.5->spacy<3.4,>=2.1.0->allennlp)\n","  Downloading pathlib_abc-0.1.1-py3-none-any.whl.metadata (18 kB)\n","Collecting commonmark<0.10.0,>=0.9.0 (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp)\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp) (2.18.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.4,>=2.1.0->allennlp) (3.0.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.67->boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.8.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp) (5.0.1)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.66.0)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.25.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (4.9)\n","Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.6.0)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.4,>=2.1.0->allennlp) (1.2.1)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.6.1)\n","Downloading allennlp-2.10.1-py3-none-any.whl (730 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.2/730.2 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n","Downloading cached_path-1.1.6-py3-none-any.whl (26 kB)\n","Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filelock-3.7.1-py3-none-any.whl (10 kB)\n","Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading spacy-3.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typer-0.4.2-py3-none-any.whl (27 kB)\n","Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading boto3-1.35.67-py3-none-any.whl (139 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pathy-0.11.0-py3-none-any.whl (47 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pathlib_abc-0.1.1-py3-none-any.whl (23 kB)\n","Downloading pydantic-1.8.2-py3-none-any.whl (126 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rich-12.6.0-py3-none-any.whl (237 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n","Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading thinc-8.0.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (659 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m659.5/659.5 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n","Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n","Downloading botocore-1.35.67-py3-none-any.whl (13.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: fairscale, termcolor, jsonnet, pathtools\n","  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307220 sha256=58f32b90d3867db398fb418b86adecf306bd92563f5441ba690881ef402ce45f\n","  Stored in directory: /root/.cache/pip/wheels/a1/58/3d/e114952ab4a8f31eb9dae230658450afff986b211a5b1f2256\n","  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=57d1ffec36630b5989bc7abc79ccef0a1e678de71dabcc7d53a0c94ba69dc052\n","  Stored in directory: /root/.cache/pip/wheels/a1/49/46/1b13a65d8da11238af9616b00fdde6d45b0f95d9291bac8452\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jsonnet: filename=jsonnet-0.20.0-cp310-cp310-linux_x86_64.whl size=6406866 sha256=0c744aefc2ddb3ba10af99cf8ddb30d858a917a59ee5f9e0dcc61efe8af5e195\n","  Stored in directory: /root/.cache/pip/wheels/63/0d/6b/5467dd1db9332ba4bd5cf4153e2870c5f89bb4db473d989cc2\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8793 sha256=3d1315f11d198270f232309bf847fe2ea603319fd0737021b99b5d94259b061b\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built fairscale termcolor jsonnet pathtools\n","Installing collected packages: wasabi, tokenizers, termcolor, pathtools, lmdb, jsonnet, commonmark, typing-extensions, typer, smart-open, shortuuid, sacremoses, rich, protobuf, pathlib-abc, jmespath, filelock, dill, base58, torch, tensorboardX, pydantic, pathy, huggingface-hub, botocore, wandb, transformers, torchvision, thinc, s3transfer, fairscale, spacy, boto3, cached-path, allennlp\n","  Attempting uninstall: wasabi\n","    Found existing installation: wasabi 1.1.3\n","    Uninstalling wasabi-1.1.3:\n","      Successfully uninstalled wasabi-1.1.3\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.20.3\n","    Uninstalling tokenizers-0.20.3:\n","      Successfully uninstalled tokenizers-0.20.3\n","  Attempting uninstall: termcolor\n","    Found existing installation: termcolor 2.5.0\n","    Uninstalling termcolor-2.5.0:\n","      Successfully uninstalled termcolor-2.5.0\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.12.2\n","    Uninstalling typing_extensions-4.12.2:\n","      Successfully uninstalled typing_extensions-4.12.2\n","  Attempting uninstall: typer\n","    Found existing installation: typer 0.13.0\n","    Uninstalling typer-0.13.0:\n","      Successfully uninstalled typer-0.13.0\n","  Attempting uninstall: smart-open\n","    Found existing installation: smart-open 7.0.5\n","    Uninstalling smart-open-7.0.5:\n","      Successfully uninstalled smart-open-7.0.5\n","  Attempting uninstall: rich\n","    Found existing installation: rich 13.9.4\n","    Uninstalling rich-13.9.4:\n","      Successfully uninstalled rich-13.9.4\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 4.25.5\n","    Uninstalling protobuf-4.25.5:\n","      Successfully uninstalled protobuf-4.25.5\n","  Attempting uninstall: filelock\n","    Found existing installation: filelock 3.16.1\n","    Uninstalling filelock-3.16.1:\n","      Successfully uninstalled filelock-3.16.1\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cu121\n","    Uninstalling torch-2.5.1+cu121:\n","      Successfully uninstalled torch-2.5.1+cu121\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 2.9.2\n","    Uninstalling pydantic-2.9.2:\n","      Successfully uninstalled pydantic-2.9.2\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.26.2\n","    Uninstalling huggingface-hub-0.26.2:\n","      Successfully uninstalled huggingface-hub-0.26.2\n","  Attempting uninstall: wandb\n","    Found existing installation: wandb 0.18.7\n","    Uninstalling wandb-0.18.7:\n","      Successfully uninstalled wandb-0.18.7\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.46.2\n","    Uninstalling transformers-4.46.2:\n","      Successfully uninstalled transformers-4.46.2\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.20.1+cu121\n","    Uninstalling torchvision-0.20.1+cu121:\n","      Successfully uninstalled torchvision-0.20.1+cu121\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.2.5\n","    Uninstalling thinc-8.2.5:\n","      Successfully uninstalled thinc-8.2.5\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.7.5\n","    Uninstalling spacy-3.7.5:\n","      Successfully uninstalled spacy-3.7.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sqlalchemy 2.0.36 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n","accelerate 1.1.1 requires huggingface-hub>=0.21.0, but you have huggingface-hub 0.10.1 which is incompatible.\n","albumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 1.8.2 which is incompatible.\n","diffusers 0.31.0 requires huggingface-hub>=0.23.2, but you have huggingface-hub 0.10.1 which is incompatible.\n","en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.3.3 which is incompatible.\n","grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n","langchain 0.3.7 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.8.2 which is incompatible.\n","langchain-core 0.3.19 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.8.2 which is incompatible.\n","langchain-core 0.3.19 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\n","nibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n","openai 1.54.4 requires pydantic<3,>=1.9.0, but you have pydantic 1.8.2 which is incompatible.\n","openai 1.54.4 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.5.0 which is incompatible.\n","peft 0.13.2 requires huggingface-hub>=0.17.0, but you have huggingface-hub 0.10.1 which is incompatible.\n","peft 0.13.2 requires torch>=1.13.0, but you have torch 1.12.1 which is incompatible.\n","pydantic-core 2.23.4 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n","pymc 5.18.2 requires rich>=13.7.1, but you have rich 12.6.0 which is incompatible.\n","pytensor 2.26.3 requires filelock>=3.15, but you have filelock 3.7.1 which is incompatible.\n","sentence-transformers 3.2.1 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.10.1 which is incompatible.\n","sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.20.1 which is incompatible.\n","torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.12.1 which is incompatible.\n","typeguard 4.4.1 requires typing-extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed allennlp-2.10.1 base58-2.1.1 boto3-1.35.67 botocore-1.35.67 cached-path-1.1.6 commonmark-0.9.1 dill-0.3.9 fairscale-0.4.6 filelock-3.7.1 huggingface-hub-0.10.1 jmespath-1.0.1 jsonnet-0.20.0 lmdb-1.5.1 pathlib-abc-0.1.1 pathtools-0.1.2 pathy-0.11.0 protobuf-3.20.3 pydantic-1.8.2 rich-12.6.0 s3transfer-0.10.4 sacremoses-0.1.1 shortuuid-1.0.13 smart-open-6.4.0 spacy-3.3.3 tensorboardX-2.6.2.2 termcolor-1.1.0 thinc-8.0.17 tokenizers-0.12.1 torch-1.12.1 torchvision-0.13.1 transformers-4.20.1 typer-0.4.2 typing-extensions-4.5.0 wandb-0.12.21 wasabi-0.10.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"079c557fddd64949b7fbe272bc0ed07a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting contractions\n","  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n","Collecting textsearch>=0.0.21 (from contractions)\n","  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n","Collecting anyascii (from textsearch>=0.0.21->contractions)\n","  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n","Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n","  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (13 kB)\n","Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n","Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n","Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n","Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"]}],"source":["!pip install allennlp\n","!pip install contractions"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1510,"status":"ok","timestamp":1732264785250,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"},"user_tz":-60},"id":"heRZF9IJWU2M","outputId":"c27c56a9-bc17-425f-caf1-8f47c823e354","collapsed":true},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["#EJECUTAR DOS VECES\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from nltk.tokenize import TreebankWordTokenizer, sent_tokenize\n","#from nltk.tokenize import sent_tokenize, RegexpTokenizer\n","from collections import Counter\n","import re\n","from nltk.corpus import stopwords\n","import pandas as pd\n","import json\n","import nltk\n","from allennlp.modules.elmo import Elmo, batch_to_ids\n","import torch\n","import math\n","from sklearn.model_selection import train_test_split\n","import contractions\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37397,"status":"ok","timestamp":1732264828706,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"},"user_tz":-60},"id":"VG_pbChSWhL7","outputId":"2e35402c-39f1-4722-81ce-14cac529b083"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","from gensim.models.keyedvectors import KeyedVectors\n","\n","#Cargamos un modelo pre-entrenado limitándolo a las 400K palabras más comunes. TODO: recuerda reemplazar el path por la localización del modelo en tu Drive.\n","word_vectors = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/NLP/Word2Vec/GoogleNews-vectors-negative300.bin.gz', binary=True, limit=400000)"]},{"cell_type":"markdown","metadata":{"id":"A7H7hbske_Fi"},"source":["Cargamos el dataset"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"xvL25WkdWWlb","executionInfo":{"status":"ok","timestamp":1732265220773,"user_tz":-60,"elapsed":1195,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"outputs":[],"source":["dt = pd.read_csv('dataset_reducido.csv')"]},{"cell_type":"markdown","source":["Eliminamos la columna features ya que la mayoria de filas estan vacias. Tambien laguange_ft y languace_cld3 que son iguales que la columna language"],"metadata":{"id":"EQ98MHgd2WD-"}},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1732265221378,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"},"user_tz":-60},"id":"M9i5yjmQrrM0","outputId":"db6de426-7ffc-4037-98c4-d9521bb8f9e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["                             title  tag           artist  year  views  \\\n","0                     Summers Over  pop  Greg MacPherson  1999     25   \n","1                          Castles  pop        bodyGaard  2020     96   \n","2  No Worries Tiëstos Big Room Mix  pop            Tisto  2017    340   \n","3          Revenge Is Sweeter Edit  pop    The Veronicas  2015    134   \n","4                        Right Now  pop   MasterClassNYC  2020     29   \n","\n","                                              lyrics       id language  \n","0  Summer's over. Calming down. All of my long sl...  1405536       en  \n","1  [Chorus]\\nSomewhere out there there’s castle f...  6742005       en  \n","2  [Verse 1]\\nI found a journal that I kept when ...  3262944       en  \n","3  I saw it in the news\\nYou told me they were wr...  1835973       en  \n","4  RIGHT NOW\\n[Malcolm X Intro]\\n\\nVerse 1\\n\\nIt'...  5630026       en  \n"]}],"source":["dt = dt.drop(columns=['features', 'language_ft', 'language_cld3'])\n","\n","print(dt.head())\n"]},{"cell_type":"markdown","source":["Imprimimos los generos que hay para saber cuantos outputs tendras el modelo que hagamos en un futuro"],"metadata":{"id":"KBo73iZ05alS"}},{"cell_type":"code","source":["genre_counts = dt['tag'].value_counts().sort_values(ascending=False)\n","\n","print(genre_counts)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rS3SUlxQ3cVL","executionInfo":{"status":"ok","timestamp":1732265223538,"user_tz":-60,"elapsed":259,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}},"outputId":"4d1c8fa8-b27e-4273-dd6f-cb64cbde98a2"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["tag\n","pop        7500\n","rap        7500\n","rock       7500\n","country    7500\n","Name: count, dtype: int64\n"]}]},{"cell_type":"markdown","metadata":{"id":"aPx8PnJdIkIQ"},"source":["### **TOKENIZACION**"]},{"cell_type":"markdown","metadata":{"id":"BP69rvDwH4MG"},"source":["Cargamos completamente la letra de una cancion para saber como es la estructura. Podemos ver que a las letras se le añaden comentarios entre corchetes."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1732265246492,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"},"user_tz":-60},"id":"mwwGgwgzHjaD","outputId":"0f2d29d6-c16b-4a16-8191-80ae6c9ef622"},"outputs":[{"output_type":"stream","name":"stdout","text":["Letra de la canción en la fila 860\n","I can't feel good\n","These thoughts about my mind, they're starting to blow\n","I will not get high\n","Cause you're the only one, to lie\n","\n","Speeding in the shadows\n","Working, when nobody knows\n","Just sit and compose\n","Screaming out slows...\n","\n","I feel complexed\n","Stress up ahead\n","I can't feel better, than before\n","I feel complexed\n","In this deadhead\n","Will this ever get an end\n","Struggling out of the blend\n","Will there ever be a day\n","When you'll finally die away\n","\n","I won't feel good\n","Blowing up thoughts, striking through the peace\n","I won't get high\n","Shaking overdrive, like a hurricane\n","Anger, pain, lies, hate\n","Love, darkness, jealousy, rage\n","Piss off, despair, satisfaction, tears\n","Hope, ignorance, shame, complex\n","\n","I feel complexed\n","Felt so afraid\n","I won't care 'bout you, anymore\n","I feel complexed\n","In this bloodshed\n","Will this ever get an end\n","Struggling out of the blend\n","Will there ever be a day\n","When you'll finally fade away\n","\n","You are my reason to try\n","You are my reason to die\n","You are my reason to lie\n","You are my reason to cry\n","\n","I feel complexed\n","Stress up ahead\n","I can't feel better than before\n","I feel complexed\n","In this deadhead\n","Will this ever get an end\n","Struggling out of the blend\n","Will there ever be a day\n","When you'll finally die away\n"]}],"source":["\n","index = 860\n","print(\"Letra de la canción en la fila\", index)\n","print(dt.loc[index, 'lyrics'])\n"]},{"cell_type":"markdown","source":["Esta funcion convierte todos los caracteres en minisculas, eliminar los comentarios entre corchetes y los caracteres que no sean letras comunes o numeros."],"metadata":{"id":"i2tWy5qJ3pqr"}},{"cell_type":"code","execution_count":19,"metadata":{"id":"a1wr8jB5WYKe","executionInfo":{"status":"ok","timestamp":1732265248924,"user_tz":-60,"elapsed":295,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"outputs":[],"source":["def preprocess_lyrics(lyrics):\n","    lyrics = lyrics.lower()\n","    lyrics = contractions.fix(lyrics)\n","    lyrics = re.sub(r'\\[.*?\\]', '', lyrics)\n","    lyrics = re.sub(r\"[^a-zA-Z0-9\\s\\n]\", '', lyrics)\n","    return lyrics.strip()"]},{"cell_type":"markdown","source":["Comprobamos que la funcion funcione con una frase ejemplo"],"metadata":{"id":"YcBEbEIPGaWE"}},{"cell_type":"code","source":["example_lyrics = \"[Intro] I'm don't know how to love you. Oh, love me like you do.\"\n","cleaned_lyrics = preprocess_lyrics(example_lyrics)\n","print(cleaned_lyrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khDDedPb9ySu","executionInfo":{"status":"ok","timestamp":1732265250724,"user_tz":-60,"elapsed":270,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}},"outputId":"ab260714-14a9-46c0-9315-c69996cdbaa1"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["i am do not know how to love you oh love me like you do\n"]}]},{"cell_type":"code","source":["dt['lyrics'] = dt['lyrics'].apply(preprocess_lyrics)"],"metadata":{"id":"lKevKgFSktOJ","executionInfo":{"status":"ok","timestamp":1732265259189,"user_tz":-60,"elapsed":7428,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["Imprimimos de nuevo una letra complleta para ver que es el formato que queremos"],"metadata":{"id":"mAQjVKbkr9Qa"}},{"cell_type":"code","source":["index = 860\n","print(\"Letra de la canción en la fila\", index)\n","print(dt.loc[index, 'lyrics'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3vKP1ONpkywF","executionInfo":{"status":"ok","timestamp":1732265259189,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}},"outputId":"fd8466e8-4e65-4888-8636-2dbcf6b6e370"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Letra de la canción en la fila 860\n","i cannot feel good\n","these thoughts about my mind they are starting to blow\n","i will not get high\n","because you are the only one to lie\n","\n","speeding in the shadows\n","working when nobody knows\n","just sit and compose\n","screaming out slows\n","\n","i feel complexed\n","stress up ahead\n","i cannot feel better than before\n","i feel complexed\n","in this deadhead\n","will this ever get an end\n","struggling out of the blend\n","will there ever be a day\n","when you will finally die away\n","\n","i will not feel good\n","blowing up thoughts striking through the peace\n","i will not get high\n","shaking overdrive like a hurricane\n","anger pain lies hate\n","love darkness jealousy rage\n","piss off despair satisfaction tears\n","hope ignorance shame complex\n","\n","i feel complexed\n","felt so afraid\n","i will not care bout you anymore\n","i feel complexed\n","in this bloodshed\n","will this ever get an end\n","struggling out of the blend\n","will there ever be a day\n","when you will finally fade away\n","\n","you are my reason to try\n","you are my reason to die\n","you are my reason to lie\n","you are my reason to cry\n","\n","i feel complexed\n","stress up ahead\n","i cannot feel better than before\n","i feel complexed\n","in this deadhead\n","will this ever get an end\n","struggling out of the blend\n","will there ever be a day\n","when you will finally die away\n"]}]},{"cell_type":"markdown","source":["Dividimos el dataset en train, validation y test"],"metadata":{"id":"-K6JYEWdruwL"}},{"cell_type":"code","execution_count":23,"metadata":{"id":"Q0A7Z1QT49ca","executionInfo":{"status":"ok","timestamp":1732265259190,"user_tz":-60,"elapsed":3,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"outputs":[],"source":["train_data, temp_data = train_test_split(dt, test_size=0.3, random_state=42)\n","\n","validation_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n","\n","dt['set_type'] = 'train'\n","dt.loc[dt.index.isin(validation_data.index), 'set_type'] = 'validation'\n","dt.loc[dt.index.isin(test_data.index), 'set_type'] = 'test'"]},{"cell_type":"code","source":["dt.rename(columns={'set_type': 'split'}, inplace=True)"],"metadata":{"id":"DIW-bkeUqAQ_","executionInfo":{"status":"ok","timestamp":1732265262059,"user_tz":-60,"elapsed":236,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["dt.to_csv('canciones.csv', index=False)"],"metadata":{"id":"PjaDlppPNnoe","executionInfo":{"status":"ok","timestamp":1732265265498,"user_tz":-60,"elapsed":1444,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["**Una vez dividido el dataset para todo el analisis que hagamos a continuacion usaremos solo la parte del dataset del**"],"metadata":{"id":"YergcsVTtzW2"}},{"cell_type":"markdown","source":["Funciones tanto para dividir por oraciones como por palabras. En la de por oraciones lo que hemos hecho es dividir cuando haya un salto de linea ya que no se usan los signos de puntuacion en las letras. Por otro lado para la funcion por tokens hemos dividido con el treebank tokenizer y eliminado las stoprwords"],"metadata":{"id":"WB1gdv_osQrh"}},{"cell_type":"code","source":["stop_words = set(stopwords.words('english'))\n","tokenizer = TreebankWordTokenizer()\n","\n","def split_into_sentences(lyrics):\n","    sections = lyrics.split('\\n')\n","    sentences = []\n","    for section in sections:\n","        if section.strip():\n","            sentences.extend(sent_tokenize(section.strip()))\n","    return sentences\n","\n","def tokenize_lyrics(lyrics):\n","    tokens = tokenizer.tokenize(lyrics)\n","    filtered_tokens = [word for word in tokens if word not in stop_words]\n","    return filtered_tokens"],"metadata":{"id":"E_nkV4cYman9","executionInfo":{"status":"aborted","timestamp":1732264765001,"user_tz":-60,"elapsed":7,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Aplicamos las funciones y comprobamos el resultado"],"metadata":{"id":"-WO59TnMtHjL"}},{"cell_type":"code","source":["nltk.download('punkt_tab')\n","train_data['sentences'] = train_data['lyrics'].apply(split_into_sentences)\n","train_data['tokens_palabras'] = train_data['lyrics'].apply(tokenize_lyrics)\n","\n","print(train_data[['title', 'sentences', 'tokens_palabras']])"],"metadata":{"id":"psnZBH1GmeDj","executionInfo":{"status":"aborted","timestamp":1732264765001,"user_tz":-60,"elapsed":7,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vemos en detalle todas las oraciones que nos genera de una cancion"],"metadata":{"id":"pVZfFdbHtSGt"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1732264765002,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"},"user_tz":-60},"id":"2PxTQqIVMQJn"},"outputs":[],"source":["index = 860\n","print(\"Oraciones de la canción en el índice\", index)\n","print(train_data.loc[index, 'sentences'])"]},{"cell_type":"markdown","source":["Creamos el bag of words"],"metadata":{"id":"IpP3cQycth5M"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1732264765002,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"},"user_tz":-60},"id":"13UsOqvDWbQH"},"outputs":[],"source":["all_words = []\n","\n","for tokens in train_data['tokens_palabras']:\n","    all_words.extend(tokens)\n","\n","bag_of_words = Counter(all_words)\n","print(bag_of_words.most_common(10))"]},{"cell_type":"markdown","metadata":{"id":"6aU1nq1dIsvN"},"source":["### **TF_IDF**"]},{"cell_type":"markdown","metadata":{"id":"HHXjOXfXIvjl"},"source":["**TF**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1732264765002,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"},"user_tz":-60},"id":"IzbJ2pycX0gJ"},"outputs":[],"source":["def compute_tf(tokens):\n","    token_count = Counter(tokens)\n","    total_tokens = len(tokens)\n","    tf_scores = {token: count / total_tokens for token, count in token_count.items()}\n","    return tf_scores\n","\n","train_data['tf'] = train_data['tokens_palabras'].apply(lambda x: compute_tf(x))\n","\n","\n","all_tf_scores = []\n","for tf_dict in train_data['tf']:\n","    all_tf_scores.extend(tf_dict.items())\n","\n","tf_top5 = pd.DataFrame(all_tf_scores, columns=['term', 'tf']).nlargest(10, 'tf')\n","tf_bottom5 = pd.DataFrame(all_tf_scores, columns=['term', 'tf']).nsmallest(10, 'tf')\n","\n","print(\"Top 5 términos con mayor TF:\\n\", tf_top5)\n","print(\"\\nTop 5 términos con menor TF:\\n\", tf_bottom5)"]},{"cell_type":"markdown","metadata":{"id":"YE2ew3_eIyRl"},"source":["**IDF**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":317610,"status":"aborted","timestamp":1732264765002,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"},"user_tz":-60},"id":"lfOnMP1NbtxL"},"outputs":[],"source":["N = len(train_data)\n","\n","def calculate_document_frequencies(token_lists):\n","    df = Counter()\n","    for tokens in token_lists:\n","        unique_tokens = set(tokens)\n","        for token in unique_tokens:\n","            df[token] += 1\n","    return df\n","\n","document_frequencies = calculate_document_frequencies(train_data['tokens_palabras'])\n","\n","def calculate_idf(df, total_documents):\n","    idf = {word: math.log(total_documents / df[word]) for word in df}\n","    return idf\n","\n","idf = calculate_idf(document_frequencies, N)\n","\n","all_idf_scores = list(idf.items())\n","\n","idf_df = pd.DataFrame(all_idf_scores, columns=['term', 'idf'])\n","\n","idf_top5 = idf_df.nlargest(5, 'idf')\n","idf_bottom5 = idf_df.nsmallest(5, 'idf')\n","\n","print(\"Top 5 términos con mayor IDF:\\n\", idf_top5)\n","print(\"\\nTop 5 términos con menor IDF:\\n\", idf_bottom5)"]},{"cell_type":"markdown","metadata":{"id":"Dp3WDVeOI118"},"source":["**TF-IDF**"]},{"cell_type":"markdown","source":["Una vez tenemos el tf y el idf podemos obtener el tf-idf"],"metadata":{"id":"5xB-Ajxiwuq-"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":317609,"status":"aborted","timestamp":1732264765003,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"},"user_tz":-60},"id":"zyh8CwsYb2Xb"},"outputs":[],"source":["def calculate_tf_idf(tf_dict, idf_dict):\n","    tf_idf = {word: tf_value * idf_dict.get(word, 0) for word, tf_value in tf_dict.items()}\n","    return tf_idf\n","\n","train_data['tf_idf'] = train_data['tf'].apply(lambda tf: calculate_tf_idf(tf, idf))\n","\n","print(train_data[['tf_idf']].head(10))\n"]},{"cell_type":"markdown","source":["Generamos las 5 palabras con mayor y menor tf-idf"],"metadata":{"id":"0fMJpDVPw9Ub"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":317608,"status":"aborted","timestamp":1732264765003,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"},"user_tz":-60},"id":"EJPBrv0Ycpxv"},"outputs":[],"source":["def find_top_bottom_tfidf(tfidf_series, top_n=10):\n","    all_tfidf = pd.Series({word: score for tfidf in tfidf_series for word, score in tfidf.items()})\n","    top_tfidf = all_tfidf.nlargest(top_n)\n","    bottom_tfidf = all_tfidf.nsmallest(top_n)\n","    return top_tfidf, bottom_tfidf\n","\n","top_tfidf, bottom_tfidf = find_top_bottom_tfidf(train_data['tf_idf'])\n","\n","print(\"Top 5 palabras con mayor TF-IDF:\")\n","print(top_tfidf)\n","\n","print(\"\\nTop 5 palabras con menor TF-IDF:\")\n","print(bottom_tfidf)\n","\n"]},{"cell_type":"code","source":["\n","tfidf_vectorizer = TfidfVectorizer()\n","tfidf_matrix = tfidf_vectorizer.fit_transform(train_data['tokens_palabras'].apply(lambda x: ' '.join(x)))\n","words = tfidf_vectorizer.get_feature_names_out()\n","tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=words)\n","tfidf_df['tag'] = train_data['tag']\n","genre_tfidf_avg = tfidf_df.groupby('tag').mean()\n"],"metadata":{"id":"voq5WGuz6wEf","executionInfo":{"status":"aborted","timestamp":1732264765003,"user_tz":-60,"elapsed":317607,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["top_tfidf_by_genre = genre_tfidf_avg.apply(lambda x: x.nlargest(10).index.tolist(), axis=1)\n","print(\"Top términos por género o artista:\\n\", top_tfidf_by_genre)\n"],"metadata":{"id":"qm6_ewOK7iRW","executionInfo":{"status":"aborted","timestamp":1732264765003,"user_tz":-60,"elapsed":317607,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IqrBaE_YIILp"},"source":["### **NO CONTEXTUALES: Word2Vec**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VDooINRRDXYI","executionInfo":{"status":"aborted","timestamp":1732264765003,"user_tz":-60,"elapsed":317607,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"outputs":[],"source":["not_in_vocab_words = []\n","\n","for word in all_words:\n","    if word not in word_vectors.key_to_index:\n","        not_in_vocab_words.append(word)\n","\n","total_words = len(all_words)\n","not_in_vocab_count = len(not_in_vocab_words)\n","percentage_not_in_vocab = (not_in_vocab_count / total_words) * 100 if total_words > 0 else 0\n","\n","print(f'Total de palabras en el dataset: {total_words}')\n","print(f'Palabras no representables con Word2Vec: {not_in_vocab_count}')\n","print(f'Porcentaje de palabras no representables: {percentage_not_in_vocab:.2f}%')\n"]},{"cell_type":"markdown","source":["Aqui podemosver algunas de las palabras de nuestro dataset que no estan reprensentadas en el word2vec. En general lo que esperabamos palabras inventdas, mal escritas, nombres..."],"metadata":{"id":"CcbXBKm-xHIO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lipi0bsprh2y","executionInfo":{"status":"aborted","timestamp":1732264765003,"user_tz":-60,"elapsed":317606,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"outputs":[],"source":["print(\"Algunas palabras no representadas por Word2Vec:\")\n","for word in not_in_vocab_words[:20]:\n","    print(word)"]},{"cell_type":"markdown","source":["Al comprobar las palabras no reprensentadas aqui si que podemos ver que hay algunas palabras que no estan reconocidas por las contracciones. Sin embargo, hemos comprobado que si al limpiar las lyrics hubiesemos dejado la comilla el resultado era peor ya que el porcentaje de palabras no representadas era mayor asi que hemos decidido dejarlo de esta manera que es la que mejor resultado nos daba."],"metadata":{"id":"L9M05ajSxU6L"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ybn3Ynn2sPBm","executionInfo":{"status":"aborted","timestamp":1732264765003,"user_tz":-60,"elapsed":317606,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"outputs":[],"source":["not_in_vocab_counter = Counter(not_in_vocab_words)\n","\n","print(\"\\nPalabras no representadas que más se repiten:\")\n","for word, count in not_in_vocab_counter.most_common(10):\n","    print(f\"{word}: {count}\")"]},{"cell_type":"markdown","source":["Hacemos una comprobacion extra y vemos si las palabras que mas se repiten en nuestro corpues estan representadas en word2vec y podemos ver que estan todas representadas"],"metadata":{"id":"zj3nJljTzKG_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"w7q-FaEDC30E","executionInfo":{"status":"aborted","timestamp":1732264765003,"user_tz":-60,"elapsed":317606,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"outputs":[],"source":["def check_word_in_word2vec(word_list, word_vectors):\n","    for word in word_list:\n","        if word in word_vectors.key_to_index:\n","            print(f\"La palabra '{word}' está en el vocabulario de Word2Vec.\")\n","        else:\n","            print(f\"La palabra '{word}' NO está en el vocabulario de Word2Vec.\")\n","\n","words_to_check = [\"i'm\",\"didn't\"]\n","most_common_words = [word for word, count in bag_of_words.most_common(20)]\n","\n","check_word_in_word2vec(most_common_words, word_vectors)\n"]},{"cell_type":"markdown","metadata":{"id":"eMQWEqU_H-gT"},"source":["### **CONTEXTUALES: ELMO**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y-_y_iqRZhrB","executionInfo":{"status":"aborted","timestamp":1732264765004,"user_tz":-60,"elapsed":317606,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"outputs":[],"source":["options_file = \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n","weight_file = \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EBpMG2ZWcvYg","executionInfo":{"status":"aborted","timestamp":1732264765004,"user_tz":-60,"elapsed":317606,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"outputs":[],"source":["elmo = Elmo(options_file, weight_file, 1, dropout=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G9aeTUhufmbV","executionInfo":{"status":"aborted","timestamp":1732264765004,"user_tz":-60,"elapsed":317606,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"outputs":[],"source":["def get_elmo_embeddings(sentences):\n","    character_ids = batch_to_ids(sentences)\n","    embeddings = elmo(character_ids)\n","    return embeddings['elmo_representations'][0]"]},{"cell_type":"markdown","source":["Comprobamos con una pequeña muestra que elmo funcione ya que lo usaremos mas adelante con machine learning"],"metadata":{"id":"8O8JwP_1zZ7O"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VEpjt349bJbB","executionInfo":{"status":"aborted","timestamp":1732264765004,"user_tz":-60,"elapsed":317605,"user":{"displayName":"Alejandro Contreras Alegría","userId":"10102862949329207256"}}},"outputs":[],"source":["sample_songs = train_data['sentences'].sample(n=3).tolist()\n","elmo_embeddings = get_elmo_embeddings(sample_songs)\n","print(elmo_embeddings)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}